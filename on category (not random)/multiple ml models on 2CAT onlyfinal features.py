#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Mon Jul 15 15:48:45 2024

@author: hpc
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, classification_report
import xgboost as xgb
import matplotlib.pyplot as plt

#LOADING THE DATA
csv_file = '/home/hpc/Desktop/finalfeatures.csv'
df = pd.read_csv(csv_file)

#FILTERING THE DATA
df_filtered = df[df['Category'].isin(['Scareware', 'Backdoor'])]
print("Filtered Data:\n", df_filtered.head(9), "\n")

#ENCODING LABELS
label_encoder = LabelEncoder()
df_filtered['Category'] = label_encoder.fit_transform(df_filtered['Category'])
print("Encoded Labels:\n", df_filtered.head(9), "\n")

#SEPARATING FEATURES AND LABELS 
X = df_filtered.drop(['Category'], axis=1)
y = df_filtered['Category']

#NORMALIZING FEATURES
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
print("Normalized Features:\n", pd.DataFrame(X_scaled, columns=X.columns).head(), "\n")

#SPLITTING THE DATA
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)
print("Training Set Shape:", X_train.shape, y_train.shape)
print("Testing Set Shape:", X_test.shape, y_test.shape, "\n")

# Define models
models = {
    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),
    'Logistic Regression': LogisticRegression(random_state=42),
    'SVM': SVC(kernel='linear', random_state=42),
    'Decision Tree': DecisionTreeClassifier(random_state=42),
    'Gradient Boosting': GradientBoostingClassifier(random_state=42),
    'XGBoost': xgb.XGBClassifier(random_state=42)
}
# Dictionary to store model accuracies
model_accuracies = {}

# Train and evaluate each model
for model_name, model in models.items():
    print(f"Training {model_name}...")
    model.fit(X_train, y_train)
    
    # Make predictions
    y_pred = model.predict(X_test)
    
    # Evaluate the model
    accuracy = accuracy_score(y_test, y_pred)
    report = classification_report(y_test, y_pred, target_names=label_encoder.classes_)
    
    print(f"{model_name} Accuracy: {accuracy}")
    print(f"Classification Report for {model_name}:\n{report}\n")
   # Store accuracy for plotting
    model_accuracies[model_name] = accuracy

print("Training and evaluation completed for all models.")
  
    
# Plotting accuracies
plt.figure(figsize=(10, 6))
bars = plt.bar(model_accuracies.keys(), model_accuracies.values(), color=['blue', 'green', 'red', 'purple', 'orange', 'cyan'])
plt.xlabel('Models')
plt.ylabel('Accuracy')
plt.title('Accuracy of Different Models')
plt.ylim(0, 1.2 )  # Assuming accuracy ranges from 0 to 1
plt.xticks(rotation=45)

# Annotate each bar with its accuracy
for bar in bars:
    yval = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2, yval, round(yval, 3), ha='center', va='bottom', fontsize=8)

plt.tight_layout()
plt.show()    