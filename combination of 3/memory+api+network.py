#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Thu Jul 18 17:25:24 2024

@author: hpc
"""

# MEMORY AND API and NETWORK 
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import accuracy_score, classification_report
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from xgboost import XGBClassifier
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, Conv1D, MaxPooling1D, Flatten, LSTM, Bidirectional, SimpleRNN

# Load data
csv_file = '/home/hpc/Desktop/finalfeatures.csv'
df = pd.read_csv(csv_file)

# Automatic detection of memory-related features
N_features = [col for col in df.columns if 'Network_' in col]
A_features = [col for col in df.columns if 'API_' in col]
M_features = [col for col in df.columns if 'Memory_' in col]

# Assume 'Category' column is the label you want to predict
label_column = 'Category'

# Encode labels
label_encoder = LabelEncoder()
df[label_column] = label_encoder.fit_transform(df[label_column])

# Combine features of interest
selected_features = N_features + A_features + M_features 

# Separate features and labels
X = df[selected_features]
y = df[label_column]

# Normalize features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# Define ML models
ml_models = {
    'RandomForest': RandomForestClassifier(),
    'XGBoost': XGBClassifier(),
    'LogisticRegression': LogisticRegression(),
    'GradientBoosting': GradientBoostingClassifier(),
    'SVM': SVC(),
    'DecisionTree': DecisionTreeClassifier()
}

# Train and evaluate ML models
ml_model_accuracies = {}
for model_name, model in ml_models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    ml_model_accuracies[model_name] = accuracy
    report = classification_report(y_test, y_pred, target_names=label_encoder.classes_)
    print(f"{model_name} Accuracy: {accuracy}")
    print(f"Classification Report for {model_name}:\n{report}\n")

# Define DL models
dl_models = {
    'MLP': Sequential([
        Dense(128, activation='relu', input_shape=(X_train.shape[1],)),
        Dropout(0.5),
        Dense(64, activation='relu'),
        Dense(len(df[label_column].unique()), activation='softmax')
    ]),
    'CNN': Sequential([
        Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)),
        MaxPooling1D(pool_size=2),
        Flatten(),
        Dense(len(df[label_column].unique()), activation='softmax')
    ]),
    'RNN': Sequential([
        SimpleRNN(64, input_shape=(X_train.shape[1], 1)),
        Dense(len(df[label_column].unique()), activation='softmax')
    ]),
    'LSTM': Sequential([
        LSTM(64, input_shape=(X_train.shape[1], 1)),
        Dense(len(df[label_column].unique()), activation='softmax')
    ]),
    'Bidirectional LSTM': Sequential([
        Bidirectional(LSTM(64), input_shape=(X_train.shape[1], 1)),
        Dense(len(df[label_column].unique()), activation='softmax')
    ])
}

# Dictionary to store DL model accuracies
dl_model_accuracies = {}

# Train and evaluate each DL model
for model_name, model in dl_models.items():
    print(f"Training {model_name}...")
    
    # Reshape input data for models that require 3D input (e.g., CNN, RNN, LSTM)
    if 'CNN' in model_name or 'RNN' in model_name or 'LSTM' in model_name or 'Bidirectional LSTM' in model_name:
        X_train_3d = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)
        X_test_3d = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)
        model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
        model.fit(X_train_3d, y_train, epochs=50, batch_size=32, verbose=0)
    else:
        model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
        model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=0)
    
    # Evaluate the model
    loss, accuracy = model.evaluate(X_test_3d if 'CNN' in model_name or 'RNN' in model_name or 'LSTM' in model_name or 'Bidirectional LSTM' in model_name else X_test, y_test, verbose=0)
    dl_model_accuracies[model_name] = accuracy
    print(f"{model_name} Accuracy: {accuracy}")

# Combine ML and DL model accuracies for comparison
print("ML Model Accuracies:", ml_model_accuracies)
print("DL Model Accuracies:", dl_model_accuracies)

# Plot the accuracies with annotations and different colors
plt.figure(figsize=(14, 7))

# Combine both dictionaries
all_model_accuracies = {**ml_model_accuracies, **dl_model_accuracies}

# Define a list of colors
colors = plt.cm.tab20(np.linspace(0, 1, len(all_model_accuracies)))

# Plot bars
bars = plt.bar(all_model_accuracies.keys(), all_model_accuracies.values(), color=colors)

# Annotate the bars with the accuracy values
for bar in bars:
    yval = bar.get_height()
    plt.text(bar.get_x() + bar.get_width() / 2.0, yval, round(yval, 4), va='bottom', ha='center', color='black', fontsize=9)

plt.xlabel('Model')
plt.ylabel('Accuracy')
plt.title('Model Accuracies Comparison')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()
